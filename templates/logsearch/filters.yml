properties:
  logstash_parser:
    filters: |
      <%=      if [@type] in ["syslog", "relp"] {
        # syslog/relp
        
        grok {
            match => { "@message" => "(?:%{INT:syslog6587_msglen} )?<%{POSINT:syslog_pri}>(?:%{NONNEGINT:syslog5424_ver} )?(?:%{SYSLOGTIMESTAMP:syslog_timestamp}|%{TIMESTAMP_ISO8601:syslog_timestamp}) %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?(:)? %{GREEDYDATA:syslog_message}" }
      #      add_field => [ "received_at", "%{@timestamp}" ]
      #      add_field => [ "received_from", "%{host}" ]
            add_tag => [ "syslog_standard" ]
            tag_on_failure => ["_grokparsefailure-syslog_standard2"]
        }
        
        if !("_grokparsefailure-syslog_standard" in [tags]) {
            syslog_pri { }
        
            date {
                match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601" ]
                timezone => "UTC"
            }
        
            # hostname: handle syslog configurations where hostname is localhost
            if ([syslog_hostname] == "localhost" ) {
                grok {
                    match => { "received_from" => "%{IPORHOST:syslog_hostname}(?::%{POSINT:syslog_port})?" }
                    overwrite => [ "syslog_hostname", "syslog_port" ]
                    tag_on_failure => [ "_grokparsefailure-syslog_standard-hostname"]
                }
            }
        
            mutate {
                replace => [ "@source.host", "%{syslog_hostname}" ]
            }
        
            mutate {
                convert => [ "syslog5424_ver", "integer" ]
                convert => [ "syslog6587_msglen", "integer" ]
                remove_field => [
                    #"syslog_pri",
                    "syslog_hostname",
                    "syslog_port",
                    "syslog_timestamp"
                ]
            }
        }
      
      }
      
      if [@type] == "syslog" and [syslog_message] =~ /^\- \- \[NXLOG/ {
        grok {
            match => [ "syslog_message", "\- \- \[NXLOG@14506 (?<shipper[source_params]>[^\]]+)\] %{GREEDYDATA:@message}" ]
            overwrite => [
                "@message"
            ]
            tag_on_failure => [ "_grokparsefailure-nxlog_standard" ]
        }
        
        if "_grokparsefailure-nxlog_standard" not in [tags] {
            # grok doesn't like @named groups
            mutate {
                rename => [ "shipper", "@shipper" ]
            }
        
            kv {
              source => "@shipper[source_params]"
              target => "@source"
            }
        
            mutate {
                # syslog is just the transport; no need to store
                remove_field => "syslog_message"
                remove_field => "syslog_pri"
                remove_field => "syslog5424_ver"
                remove_field => "syslog_program"
                remove_field => "syslog_severity_code"
                remove_field => "syslog_facility_code"
                remove_field => "syslog_facility"
                remove_field => "syslog_severity"
        
                # syslog host is actually the shipper
                rename => [ "@source.host", "@shipper[host]" ]
        
                # these arbitrary parameters are parsed to @source
                remove_field => "@shipper[source_params]"
        
                # these are parsed with kv, but they're static nxlog shipper properties
                rename => [ "@source[EventReceivedTime]", "@shipper[event_received_time]" ]
                rename => [ "@source[SourceModuleName]", "@shipper[module_name]" ]
                rename => [ "@source[SourceModuleType]", "@shipper[module_type]" ]
        
                # @source[type] should replace the syslog @type
                rename => [ "@source[type]", "@type" ]
            }
        }
      
      }
      
      if [@type] == "json" {
        json {
          source => "@message"
        }
        
        date {
          match => [ "timestamp", "ISO8601" ]
          timezone => "UTC"
        }
        
        
        #
        # typically message will be a string, so message_data is used as the object
        #
        
        ruby {
          code => "event['message_data'] = event.remove('message') if event.include?('message') and event['message'].is_a? Hash"
        }
        
        if [@timestamp] {
          #
          # We ran into a situation where a shipper was sending an improperly formatted
          # message into the logsearch cluster. It included a raw @timestamp field, but
          # it was an array. This causes the logstash parsing process to completely block
          # because it is unable to convert event['@timestamp'] since it expects a Time.
          #
          # This performs a check to ensure @timestamp is a Time, otherwise it renames
          # the field to _timestamperror, adds a _timestamperror tag, and replaces
          # @timestamp with the current time.
          #
        
          ruby {
            code => "if Time != event['@timestamp'].class ; event.tag('_timestamperror') ; event['_timestamperror'] = event['@timestamp'] ; event['@timestamp'] = Time.new ; end"
          }
        }
      
      }
      
      if [@type] == "elasticsearch_request" {
        json {
          source => "@message"
        }
        
        mutate {
          remove_field => [ 'day', 'dow', 'hour', 'minute', 'month', 'year' ]
        }
        
        date {
          match => [ "starttime", "ISO8601" ]
          timezone => "UTC"
        }
      
      }
      
      if [@type] == "nginx_combined" {
        grok {
          match => [ "@message", "%{IPORHOST:remote_addr} - (?:%{USER:remote_user}|-) \[%{HTTPDATE:time_local}\] \"(?:%{WORD:request_method} %{URIPATHPARAM:request_uri}(?: HTTP/%{NUMBER:request_httpversion})?|-)\" %{INT:status} (?:%{NONNEGINT:body_bytes_sent}|-) \"(?:%{URI:http_referer}|-)\" %{QS:http_user_agent} (?:%{NONNEGINT:request_time}|-)" ]
          match => [ "@message", "%{IPORHOST:remote_addr} - (?:%{USER:remote_user}|-) \[%{HTTPDATE:time_local}\] \"(?:%{WORD:request_method} %{URIPATHPARAM:request_uri}(?: HTTP/%{NUMBER:request_httpversion})?|-)\" %{INT:status} (?:%{NONNEGINT:body_bytes_sent}|-) \"(?:%{URI:http_referer}|-)\" %{QS:http_user_agent}" ]
          add_tag => "nginx"
          tag_on_failure => [ "_grokparsefailure-nginx_combined" ]
        }
        
        date {
          match => [ "time_local", "dd/MMM/YYYY:HH:mm:ss Z" ]
          timezone => "UTC"
        }
        
        mutate {
          convert => [ "status", "integer" ]
          convert => [ "body_bytes_sent", "integer" ]
          convert => [ "request_time", "integer" ]
        }
      
      }
      # Parse Cloud Foundry logs from loggregator (syslog)
      # see https://github.com/cloudfoundry/loggregator/blob/master/src/loggregator/sinks/syslogwriter/syslog_writer.go#L156
      
      if [@type] in ["syslog", "relp"] and [@source.host] == "loggregator" {
        # Parse Cloud Foundry logs from loggregator (syslog)
        # see https://github.com/cloudfoundry/loggregator/blob/master/src/loggregator/sinks/syslogwriter/syslog_writer.go#L156
        
        grok {
            match => { "syslog_message" => "\[(?<log_source>[^/\]]+)(?:/(?<log_source_id>[^\]]+))?\] \- \-(?: %{GREEDYDATA:message})?" }
            tag_on_failure => [
                "_grokparsefailure-cf-loggregator"
            ]
        }
        
        if !("_grokparsefailure-cf-loggregator" in [tags]) {
            if [message] =~ /^\s*{".*}\s*$/ {
                mutate {
                    rename => [ "message", "_message_json" ]
                }
        
                json {
                    source => "_message_json"
                }
        
                # @todo seems like some messages have @timestamp in them? seems ci-specific
                date {
                    match => [ "@timestamp", "ISO8601" ]
                }
        
                mutate {
                    remove_field => [ "_message_json" ]
                }
            }
        
            mutate {
                rename => [ "syslog_program", "@source.app_id" ]
            }
        
            mutate {
                add_tag => "cloudfoundry_loggregator"
                remove_field => "syslog_facility"
                remove_field => "syslog_facility_code"
                remove_field => "syslog_message"
                remove_field => "syslog_severity"
                remove_field => "syslog_severity_code"
                remove_field => "syslog5424_ver"
                remove_field => "syslog6587_msglen"
            }
        }
      
      } else if [@type] in ["syslog", "relp"] and [syslog_program] =~ /vcap\..*/ {
        # Parse Cloud Foundry logs from syslog_aggregator
        
        grok {
            match => { "syslog_message" => "(?:\[job=%{NOTSPACE:@job.name}|-) +(?:index=%{NOTSPACE:@job.index}\]|-) %{GREEDYDATA:_message_json}" }
            tag_on_failure => [
                "_grokparsefailure-cf-vcap"
            ]
        }
        
        if !("_grokparsefailure-cf-vcap" in [tags]) {
            kv {
                source => "msgdata"
                field_split => " "
                target => "msgdata"
            }
        
            json {
                source => "_message_json"
                remove_field => "_message_json"
            }
        
            mutate {
                rename => [ "syslog_program", "@shipper.name" ]
                replace => [ "@job.host", "%{@source.host}" ]
                gsub => [
                    "@shipper.name", "\.", "_",
                    "@job.name", "\.", "_"
                  ]
            }
        
            if [source] == "NatsStreamForwarder" {
                json {
                    source => "[data][nats_message]"
                    target => "nats_message"
                }
        
                mutate {
                    remove_field => "[data][nats_message]"
                }
            }
        
            mutate {
                add_tag => "cloudfoundry_vcap"
                replace => [ "@shipper.priority", "%{syslog_pri}" ]
                replace => [ "@shipper.name", "%{@shipper.name}_%{@type}" ]
                replace => [ "@type", "%{@type}_cf" ]
            }
        
            mutate {
                remove_field => "syslog_facility"
                remove_field => "syslog_facility_code"
                remove_field => "syslog_message"
                remove_field => "syslog_severity"
                remove_field => "syslog_severity_code"
            }
        }
      
      }
